minikube ip : to find the IP address of the node in the cluster. We can use this ip add to communicate using SSH. 

    SSH is a protocol for management of any servers (including remote servers). Minikube also provides commands to SSH into the local minikube node “minikube ssh”
    If we set —driver = docker we should use minikube ssh because ssh docker@<minkube ip> will not work. Otherwise we can use ssh docker@minikube ip
    Minkube node user credentials : username:   docker / password : tcuser 
    Now, we are inside docker node, we can the docker commands to run, check all running containers and other commands (Docker is the default container runtime in Kubernetes).
    Minikube has already created some containers like the api server, controller, scheduler, controller, etc. These are basically the services that we saw run inside the master node. But in minikube these services are run inside the containers. 
    Now, if we use kubectl command, it will not be recognized here, as it is use to manage cluster and is not usable inside node. Will give error command not found. It can be used only outside node.
    To get out of the node, exit


    Kubectl commands
    Checking cluster info : kubectl cluster-info

	(base) user@Dhanupriya-Office ~ % kubectl cluster-info  

	Kubernetes control plane is running at https://192.168.59.100:8443

	CoreDNS is running at https://192.168.59.100:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

    Now, we can create deployment, services, and others in our cluster.


    Get all nodes - minkube has only one node that will act as both master and worker, so will see only one node.

(base) user@Dhanupriya-Office ~ % kubectl get nodes

NAME       STATUS   ROLES           AGE   VERSION

minikube   Ready    control-plane   27m   v1.24.3


    Get all pods - we don’t have any pods available, we will need to create (this command will check only the available pods in the default namespace : namespace discuss below)

(base) user@Dhanupriya-Office ~ % kubectl get pods

No resources found in default namespace.


    Get namespaces : namespaces are used to group different resources, configurations and objects

(base) user@Dhanupriya-Office ~ % kubectl get namespaces

NAME              STATUS   AGE

default           Active   40m

kube-node-lease   Active   40m

kube-public       Active   40m

kube-system       Active   40m


    To get pods running in any of the namespace other than default: (the below pods are all system pods which are running in master node)

(base) user@Dhanupriya-Office ~ % kubectl get pods --namespace=kube-system

NAME                               READY   STATUS    RESTARTS      AGE

coredns-6d4b75cb6d-62pdm           1/1     Running   0             42m

etcd-minikube                      1/1     Running   0             43m

kube-apiserver-minikube            1/1     Running   0             43m

kube-controller-manager-minikube   1/1     Running   0             43m

kube-proxy-ggnmt                   1/1     Running   0             42m

kube-scheduler-minikube            1/1     Running   0             43m

storage-provisioner                1/1     Running   1 (42m ago)   43m


—CREATING POD—

    This is similar to creating container in Docker : syntax -> kubectl run pod_nam —image=image_name
    Lets create a pod using nginx image

(base) user@Dhanupriya-Office ~ % kubectl run nginx --image=nginx

pod/nginx created

(base) user@Dhanupriya-Office ~ % kubectl get pods

NAME    READY   STATUS              RESTARTS   AGE

nginx   0/1     ContainerCreating   0          6s

(base) user@Dhanupriya-Office ~ % kubectl get pods

NAME    READY   STATUS    RESTARTS   AGE

nginx   1/1     Running   0          24s


    To get details of a running pod: kubectl describe pod pod_name

(base) user@Dhanupriya-Office ~ % kubectl describe pod nginx

Name:         nginx

Namespace:    default

Priority:     0

Node:         minikube/192.168.59.100.  —> Kubernetes basically selects the worker node where to create the container, but here in minikube, since there is only one node.. this is being assigned by default.

Start Time:   Mon, 22 Aug 2022 10:24:43 +0530

Labels:       run=nginx

Annotations:  <none>

Status:       Running

IP:           172.17.0.3  ——>(we cannot use this internal IP address to access this container, for this we will need to create service to connect and access this container)



    Getting inside the pod again and check the running containers in it. (base) user@Dhanupriya-Office ~ % ssh docker@192.168.59.100
    Checking all running containers (greping that contains nginx)

$ docker ps | grep nginx

cea491d3c4cc   nginx                  "/docker-entrypoint.…"   30 minutes ago      Up 30 minutes                k8s_nginx_nginx_default_27463443-88db-4235-9772-874014202652_0

250d0e09c1e1   k8s.gcr.io/pause:3.6   "/pause"                 30 minutes ago      Up 30 minutes                k8s_POD_nginx_default_27463443-88db-4235-9772-874014202652_0

    The second container is a pause container where a pause executable is launched. If Docker is the container runtime, then this pause container is always created for each specific pod. These are created to lock namespace of specific pod and we know that containers inside a pod share same namespace. 
    The other container that we created can be stop, pause and recreated but the pod will remain untouched, so this second container (pause container) is required to keep the namespace of the pod to keep it functional.


Connecting to the container running :

    Lets connect to our first container

$ docker exec -it cea491d3c4cc sh

# hostname.   —> getting the hostname of the container (same name is given in this case)

nginx

# hostname -i              —> IP address of the pod running the container , this is the one that we saw in the details info above.

172.17.0.3


Getting into the container and try to run the nginx web server that was hosted by the container.

# curl 172.17.0.3

<!DOCTYPE html>

<html>

<head>

<title>Welcome to nginx!</title>

<style>

html { color-scheme: light dark; }

body { width: 35em; margin: 0 auto;

font-family: Tahoma, Verdana, Arial, sans-serif; }

</style>

</head>

<body>

<h1>Welcome to nginx!</h1>

<p>If you see this page, the nginx web server is successfully installed and

working. Further configuration is required.</p>


<p>For online documentation and support please refer to

<a href="http://nginx.org/">nginx.org</a>.<br/>

Commercial support is available at

<a href="http://nginx.com/">nginx.com</a>.</p>


<p><em>Thank you for using nginx.</em></p>

</body>

</html> 

— This is the response from the web server. And now we can see it is successfully being launched.


(base) user@Dhanupriya-Office ~ % kubectl get pods -o wide

NAME    READY   STATUS    RESTARTS   AGE   IP           NODE       NOMINATED NODE   READINESS GATES

nginx   1/1     Running   0          77m   172.17.0.3   minikube   <none>           <none>

—> Here, we can see the IP address of the pod. For multiple containers also, we will see the same IP address, as they are on the same node in minikube.


    Now lets try to connect to this container from our system (earlier we went inside the container and then access), we can do this by creating services.
    Our system is external to this as the container is running in a node that is inside a virtual machine.  


DELETING pod - kubectl delete pod pod_name —> this will remove the pod and release all resources held by this pod

(base) user@Dhanupriya-Office ~ % kubectl delete pod nginx

pod "nginx" deleted

(base) user@Dhanupriya-Office ~ % kubectl get pods

No resources found in default namespace.


CREATING ALIAS for commands: alias k=‘kubectl’

    Since kubectl is a long word and we want to create an alias of it, where we can write commands like k get pods
    The above will not work in windows cmd and powershell in windows. Instead we will need to use gitbash in order to do this.

(base) user@Dhanupriya-Office ~ % alias k='kubectl'

(base) user@Dhanupriya-Office ~ % k get pods

No resources found in default namespace.


DEPLOYMENT:

    It is not convenient for us to create multiple pods in the way that we have created earlier if we want say multiple instances of the same image and run on different pods and distribute loads across pods, or modify configuration of the pods, etc.
    To do these activities, there is Deployment. It will take care of creating multiple instances of containers across different pods, managing and configuring them. Creation method will be similar to the way that we have created earlier.


CREATING Deployment : kubectl create deployment deployment_name —image=image_name

(base) user@Dhanupriya-Office ~ % k create deployment nginx-deployment --image=nginx

deployment.apps/nginx-deployment created

(base) user@Dhanupriya-Office ~ % k get deployments

NAME               READY   UP-TO-DATE   AVAILABLE   AGE

nginx-deployment   1/1     1            1           6s

(base) user@Dhanupriya-Office ~ % k get pods

NAME                                READY   STATUS    RESTARTS   AGE

nginx-deployment-85c6d5f6dd-s956b   1/1     Running   0          9s


    Here we can see a single pod is automatically created once the deployment is created. This pod will be managed by this deployment. We can scale the number of pods as per our needs.


DETAILS of the deployment: kubectl describe deployment deployment_name

(base) user@Dhanupriya-Office ~ % k describe deployment nginx-deployment

Name:                   nginx-deployment

Namespace:              default

CreationTimestamp:      Mon, 22 Aug 2022 12:01:58 +0530

Labels:                 app=nginx-deployment

Annotations:            deployment.kubernetes.io/revision: 1

Selector:               app=nginx-deployment   —> use to connect pod with deployments, as pods and deployments are actually separate objects and we need to know how to assign specific pods to specific deployment. Each selector will have a respective Label that we can identify.

Replicas:               1 desired | 1 updated | 1 total | 1 available | 0 unavailable —>gives number of pods desired, available or updated. For our case for now, it’s only one.

StrategyType:           RollingUpdate

MinReadySeconds:        0

RollingUpdateStrategy:  25% max unavailable, 25% max surge

Pod Template:

  Labels:  app=nginx-deployment —> like mentioned above we can this label for each pod

  Containers:

   nginx:

    Image:        nginx

    Port:         <none>

    Host Port:    <none>

    Environment:  <none>

    Mounts:       <none>

  Volumes:        <none>

Conditions:

  Type           Status  Reason

  ----           ------  ------

  Available      True    MinimumReplicasAvailable

  Progressing    True    NewReplicaSetAvailable

OldReplicaSets:  <none>

NewReplicaSet:   nginx-deployment-85c6d5f6dd (1/1 replicas created). —> replica set manages all pods related to deployment. It is the replicas set of our applications where we can create multiple pods in a deployment and they are included in this replica set

Events:

  Type    Reason             Age   From                   Message

  ----    ------             ----  ----                   -------

  Normal  ScalingReplicaSet  25m   deployment-controller  Scaled up replica set nginx-deployment-85c6d5f6dd to 1 —> this event creates one replica set where we can see one pod was automatically created with this deployment


## Getting the running pod and checking it’s details:

(base) user@Dhanupriya-Office ~ % k get pods

NAME                                READY   STATUS    RESTARTS   AGE

nginx-deployment-85c6d5f6dd-s956b   1/1     Running   0          9h

(base) user@Dhanupriya-Office ~ % k describe pod nginx-deployment-85c6d5f6dd-s956b

Name:         nginx-deployment-85c6d5f6dd-s956b

Namespace:    default

Priority:     0

Node:         minikube/192.168.59.100

Start Time:   Mon, 22 Aug 2022 12:01:58 +0530

Labels:       app=nginx-deployment

              pod-template-hash=85c6d5f6dd

Annotations:  <none>

Status:       Running

IP:           172.17.0.3

IPs:

  IP:           172.17.0.3

Controlled By:  ReplicaSet/nginx-deployment-85c6d5f6dd

Containers:

  nginx:

    Container ID:   docker://be1f52caee9f69e5c1d3af5f174f97c797aae0e637516f6dd2dab2d810625c90

    Image:          nginx

    Image ID:       docker-pullable://nginx@sha256:790711e34858c9b0741edffef6ed3d8199d8faa33f2870dea5db70f16384df79



## SCALING UP THE NUMBER OF PODS IN THE DEPLOYMENT

Command : kubectl scale deployment deployment_name —replicas=number_of_repelicas


(base) user@Dhanupriya-Office ~ %  k get deployments  

NAME               READY   UP-TO-DATE   AVAILABLE   AGE

nginx-deployment   1/1     1            1           9h

(base) user@Dhanupriya-Office ~ % k scale deployment nginx-deployment --replicas=5

deployment.apps/nginx-deployment scaled

(base) user@Dhanupriya-Office ~ % k get pods

NAME                                READY   STATUS              RESTARTS   AGE

nginx-deployment-85c6d5f6dd-2dvwq   0/1     ContainerCreating   0          4s

nginx-deployment-85c6d5f6dd-7m8rl   0/1     ContainerCreating   0          4s

nginx-deployment-85c6d5f6dd-ljsmf   0/1     ContainerCreating   0          4s

nginx-deployment-85c6d5f6dd-s956b   1/1     Running             0          9h

nginx-deployment-85c6d5f6dd-zk74p   0/1     ContainerCreating   0          4s. —> Now we can see 5 pods, 4 new pods are being added ( additional 4 new replicas are being created)


(base) user@Dhanupriya-Office ~ % k get pods

NAME                                READY   STATUS    RESTARTS   AGE

nginx-deployment-85c6d5f6dd-2dvwq   1/1     Running   0          69s

nginx-deployment-85c6d5f6dd-7m8rl   1/1     Running   0          69s

nginx-deployment-85c6d5f6dd-ljsmf   1/1     Running   0          69s

nginx-deployment-85c6d5f6dd-s956b   1/1     Running   0          9h

nginx-deployment-85c6d5f6dd-zk74p   1/1     Running   0          69s


(base) user@Dhanupriya-Office ~ % k get pods -o wide

NAME                                READY   STATUS    RESTARTS   AGE     IP           NODE       NOMINATED NODE   READINESS GATES

nginx-deployment-85c6d5f6dd-2dvwq   1/1     Running   0          2m44s   172.17.0.5   minikube   <none>           <none>

nginx-deployment-85c6d5f6dd-7m8rl   1/1     Running   0          2m44s   172.17.0.4   minikube   <none>           <none>

nginx-deployment-85c6d5f6dd-ljsmf   1/1     Running   0          2m44s   172.17.0.6   minikube   <none>           <none>

nginx-deployment-85c6d5f6dd-s956b   1/1     Running   0          10h     172.17.0.3   minikube   <none>           <none>

nginx-deployment-85c6d5f6dd-zk74p   1/1     Running   0          2m44s   172.17.0.7   minikube   <none>           <none>


    Here, we can see that the NAME of the pods have the same prefix (this prefix is the replica set ID) and for each pod, the last suffix is unique to the pod. Also, we can see these pods are running on different ip.


## scaling down :same command

(base) user@Dhanupriya-Office ~ % k scale deployment nginx-deployment --replicas=3

deployment.apps/nginx-deployment scaled

(base) user@Dhanupriya-Office ~ % k get pods -o wide                              

NAME                                READY   STATUS    RESTARTS   AGE     IP           NODE       NOMINATED NODE   READINESS GATES

nginx-deployment-85c6d5f6dd-2dvwq   1/1     Running   0          5m23s   172.17.0.5   minikube   <none>           <none>

nginx-deployment-85c6d5f6dd-ljsmf   1/1     Running   0          5m23s   172.17.0.6   minikube   <none>           <none>

nginx-deployment-85c6d5f6dd-s956b   1/1     Running   0          10h     172.17.0.3   minikube   <none>           <none>


    Now, we can see only 3 pods running, 2 are being removed.

## CONNECTING TO ANY OF THE PODS RUNNING AND ACCESSING THE WEB SERVER (we have already done this before)

    First get into the node where the minikube is running and then access the pod (do curl and then ip_address of the pod)


(base) user@Dhanupriya-Office ~ % minikube ip              

192.168.59.100

(base) user@Dhanupriya-Office ~ % ssh docker@192.168.59.100

docker@192.168.59.100's password: 

                         _             _            

            _         _ ( )           ( )           

  ___ ___  (_)  ___  (_)| |/')  _   _ | |_      __  

/' _ ` _ `\| |/' _ `\| || , <  ( ) ( )| '_`\  /'__`\

| ( ) ( ) || || ( ) || || |\`\ | (_) || |_) )(  ___/

(_) (_) (_)(_)(_) (_)(_)(_) (_)`\___/'(_,__/'`\____)


$ curl 172.17.0.6

<!DOCTYPE html>

<html>

<head>

<title>Welcome to nginx!</title>

<style>

html { color-scheme: light dark; }

body { width: 35em; margin: 0 auto;

font-family: Tahoma, Verdana, Arial, sans-serif; }

</style>

</head>

<body>

<h1>Welcome to nginx!</h1>

<p>If you see this page, the nginx web server is successfully installed and

working. Further configuration is required.</p>


<p>For online documentation and support please refer to

<a href="http://nginx.org/">nginx.org</a>.<br/>

Commercial support is available at

<a href="http://nginx.com/">nginx.com</a>.</p>


<p><em>Thank you for using nginx.</em></p>

</body>

</html>


— Here we are trying to access the running container (pod) by using it’s IP address and doing curl. It is not a convenient method. In K8S we will need to create SERVICES to connect to specific deployments using specific IP address.

    There are different options to do this, we can create a Cluster IP and such IP address will be created and assign to specific deployment and will be able to connect to such specific deployment only inside of the cluster using this virtual IP address.
    And K8s will distribute loads across different pods which are assigned to specific deployment. Such IP will be a single IP address for entire deployment. IT is a convenient method than using specific IP address of the pods as we have seen before. 
    Also there is another option to create external IP address, to open deployment to outside world and it is possible to expose specific deployment to the IP address of the node or use load balancer. Recap that inside of the K8S cluster, it is possible to have multiple nodes
    And pods could be distributed across different nodes. Therefore the most common solution is to have Load Balancer IP address which will be a single IP address for entire K8S cluster for a specific deployment and we will be able to connect to our deployment 
    No matter how many pods are created, using just single IP address. But such load balancer IP address are assigned by specific cloud provider and these assingments are managed by Cloud Controller Manager service that is running in the Master node.


Let’s try to create Cluster IP for our deployment by creating specific Service. 

    First lets get all the deployments:


(base) user@Dhanupriya-Office ~ % k get deploy

NAME               READY   UP-TO-DATE   AVAILABLE   AGE

nginx-deployment   3/3     3            3           10h


    We have a deployment that has 3 pods running, inside which nginx containers are running. Now, we will need to expose the port for these pods (for nginx, it is 80) to any other pod outside of this deployment. We can use any port say 8080 to get these internal port exposed to it. 
    We can do this using expose command: k expose deployment deployment_name —port=8080 —target-port=80 (8080 is the port that we want to get it to exposed to and target port is the internal port of the containers in the pod. No need to specify target ports if both have same port numbers)


(base) user@Dhanupriya-Office ~ % k expose deployment nginx-deployment --port=8080 --target-port=80

service/nginx-deployment exposed


    Now we have exposed internal port 80 to 8080 for this deployment. Now, lets get list of all services


(base) user@Dhanupriya-Office ~ % k get services  ( can also be done using k get svc)

NAME               TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE

kubernetes         ClusterIP   10.96.0.1      <none>        443/TCP    13h                                 —> default system service

nginx-deployment   ClusterIP   10.97.51.174   <none>        8080/TCP   76s


    If we look at the second one, that is basically the service that we will be using. The IP address is completely different from the IP address of the pods(which starts at 172), but this one starts with 10 . This is a virtual IP address created by K8S. It is a single ip add and can be used to connect to any of the pods. 
    Such ClusterIP type IP allows to connect to specific deployments, ( in our case nginx-deployement) only from inside of the K8S cluster. Say if we have a database deployment like mongoDB or SQL, they cannot be exposed to outside world but should be accessible by other deployments in the Cluster
    So, for such database type deployments, we can use this ClusterIP type IP’s. For nginx like web-server deployments, it will need to be exposed to the outside world also, in this case, we can expose it via Node Port or Load Balancer.
    So, the take here is ClusterIP is a single IP specific to a deployment, which can be used to access the pods in the deployment. K8S will take care of the distribution of loads across the pods in the deployment. It will be accessible only from inside the Cluster nodes.  


Now, lets try to connect to our deployment using this service.

(base) user@Dhanupriya-Office ~ % curl 10.97.51.174:8080

^C

    We cannot access from outside world even by using the ClusterIP and port number as mentioned. It can also be access from some node within the Cluster


(base) user@Dhanupriya-Office ~ % ssh docker@192.168.59.100                                        

docker@192.168.59.100's password: 

                         _             _            

            _         _ ( )           ( )           

  ___ ___  (_)  ___  (_)| |/')  _   _ | |_      __  

/' _ ` _ `\| |/' _ `\| || , <  ( ) ( )| '_`\  /'__`\

| ( ) ( ) || || ( ) || || |\`\ | (_) || |_) )(  ___/

(_) (_) (_)(_)(_) (_)(_)(_) (_)`\___/'(_,__/'`\____)


$ curl 10.97.51.174:8080

<!DOCTYPE html>

<html>

<head>

<title>Welcome to nginx!</title>

<style>

html { color-scheme: light dark; }

body { width: 35em; margin: 0 auto;

font-family: Tahoma, Verdana, Arial, sans-serif; }

</style>

</head>

<body>

<h1>Welcome to nginx!</h1>

<p>If you see this page, the nginx web server is successfully installed and

working. Further configuration is required.</p>


<p>For online documentation and support please refer to

<a href="http://nginx.org/">nginx.org</a>.<br/>

Commercial support is available at

<a href="http://nginx.com/">nginx.com</a>.</p>


<p><em>Thank you for using nginx.</em></p>

</body>

</html>


    Now, we can access from a node. Now, this response is given from any of the pods running in this deployment. Can be from any one of the 3 pods runnings.


## GET DETAILS OF A SERVICE

(base) user@Dhanupriya-Office ~ % k get svc

NAME               TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE

kubernetes         ClusterIP   10.96.0.1      <none>        443/TCP    13h

nginx-deployment   ClusterIP   10.97.51.174   <none>        8080/TCP   22m

(base) user@Dhanupriya-Office ~ % k describe service nginx-deployment

Name:              nginx-deployment

Namespace:         default

Labels:            app=nginx-deployment

Annotations:       <none>

Selector:          app=nginx-deployment

Type:              ClusterIP

IP Family Policy:  SingleStack

IP Families:       IPv4

IP:                10.97.51.174

IPs:               10.97.51.174

Port:              <unset>  8080/TCP

TargetPort:        80/TCP

Endpoints:         172.17.0.3:80,172.17.0.5:80,172.17.0.6:80        —> underlying pod details

Session Affinity:  None

Events:            <none>


## DELETING DEPLOYMENT AND SERVICES : lets delete the deployment and services so that we can build our own custom image, push into DockerHub and then containerize and deploy

(base) user@Dhanupriya-Office ~ % k delete deployment nginx-deployment

deployment.apps "nginx-deployment" deleted

(base) user@Dhanupriya-Office ~ % k delete service nginx-deployment

service "nginx-deployment" deleted

(base) user@Dhanupriya-Office ~ % k get deployments

No resources found in default namespace.

(base) user@Dhanupriya-Office ~ % k get svc

NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE

kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   13h

(base) user@Dhanupriya-Office ~ % k get pods

No resources found in default namespace.


## CREATING OUR OWN CUSTOM IMAGE ( will be using node js and express framework to create a simple image)


Now that we have created a very basic web server, we will try to create an image and then containerise using Docker.


DOCKERFILE contents:

FROM node:alpine


WORKDIR /app


EXPOSE 3000


COPY package.json package-lock.json ./


RUN npm install


COPY . ./


CMD ["npm","start"]


## BUILD CUSTOM IMAGE and push it to DOCKER HUB:


docker build . -t budhajit15/k8s-web-hello

docker images | grep k8s-web

docker push budhajit15/k8s-web-hello


# Now that we have build and push our image to Docker Hub, lets create our deployment using the command k create deployment k8s-web-hello-deploy —image=budhajit15/k8s-web-hello


(base) user@Dhanupriya-Office ~ % k get pods

NAME                                    READY   STATUS    RESTARTS   AGE

k8s-web-hello-deploy-549b784b54-n79q6   1/1     Running   0          62s


## now deployment is created, let’s create service to expose the deployment


(base) user@Dhanupriya-Office ~ % k expose deployment k8s-web-hello-deploy --port=3000

service/k8s-web-hello-deploy exposed

(base) user@Dhanupriya-Office ~ % k get svc

NAME                   TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE

k8s-web-hello-deploy   ClusterIP   10.104.174.44   <none>        3000/TCP   4s

kubernetes             ClusterIP   10.96.0.1       <none>        443/TCP    23h


Now  ClusterIP is created. We can use this to access this service. But only from within the node and not from outside i.e it will not be accessible from this system. We will need to get inside the minikube node and access it.


# first lets get minikube IP to do SSH

(base) user@Dhanupriya-Office ~ % minikube ip              

192.168.59.100

(base) user@Dhanupriya-Office ~ % SSH docker@192.168.59.100

docker@192.168.59.100's password: 

                         _             _            

            _         _ ( )           ( )           

  ___ ___  (_)  ___  (_)| |/')  _   _ | |_      __  

/' _ ` _ `\| |/' _ `\| || , <  ( ) ( )| '_`\  /'__`\

| ( ) ( ) || || ( ) || || |\`\ | (_) || |_) )(  ___/

(_) (_) (_)(_)(_) (_)(_)(_) (_)`\___/'(_,__/'`\____)


$ curl 10.104.174.44:3000; echo.      —> once inside the minikube, I’m able to curl using the Cluster IP given by the svc and the port number that we expose i.e. 3000

Hello from the ${os.hostname()}


# now lets SCALE the number of pods in our deployment


(base) user@Dhanupriya-Office ~ % k scale deployment k8s-web-hello-deploy --replicas=4

deployment.apps/k8s-web-hello-deploy scaled

(base) user@Dhanupriya-Office ~ % k get pods

NAME                                    READY   STATUS              RESTARTS   AGE

k8s-web-hello-deploy-549b784b54-4h4fg   0/1     ContainerCreating   0          4s

k8s-web-hello-deploy-549b784b54-bh42r   0/1     ContainerCreating   0          4s

k8s-web-hello-deploy-549b784b54-mnfb5   0/1     ContainerCreating   0          4s

k8s-web-hello-deploy-549b784b54-n79q6   1/1     Running             0          26m

(base) user@Dhanupriya-Office ~ % k get pods -o wide

NAME                                    READY   STATUS    RESTARTS   AGE   IP           NODE       NOMINATED NODE   READINESS GATES

k8s-web-hello-deploy-549b784b54-4h4fg   1/1     Running   0          20s   172.17.0.5   minikube   <none>           <none>

k8s-web-hello-deploy-549b784b54-bh42r   1/1     Running   0          20s   172.17.0.4   minikube   <none>           <none>

k8s-web-hello-deploy-549b784b54-mnfb5   1/1     Running   0          20s   172.17.0.6   minikube   <none>           <none>

k8s-web-hello-deploy-549b784b54-n79q6   1/1     Running   0          27m   172.17.0.3   minikube   <none>           <none>


    Now when we try to access the deployment using the service, the response can be fetched from any of the pods. This management and load balancing is automatically done by the Kubernetes.


## CREATING NODE PORT type service

    The service (ClusterIP) type that we have created before, is accessible only from within the node. In order to make it accessible from outside world, we will need to create service of type NODE PORT
    First lets delete our existing service and then create a node port type service


(base) user@Dhanupriya-Office ~ % k delete svc k8s-web-hello-deploy

service "k8s-web-hello-deploy" deleted

(base) user@Dhanupriya-Office ~ % k get svc

NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE

kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   24h


## CREATE node port type service


(base) user@Dhanupriya-Office ~ % k expose deployment k8s-web-hello-deploy --type=NodePort --port=3000

service/k8s-web-hello-deploy exposed

(base) user@Dhanupriya-Office ~ % k get svc

NAME                   TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE

k8s-web-hello-deploy   NodePort    10.111.97.180   <none>        3000:31208/TCP   5s

kubernetes             ClusterIP   10.96.0.1       <none>        443/TCP          24h


    We can see a NodePort type service is created. Also, a port for the service 31208 is automatically created, we can use this port to access the deployment (along with the minikube node IP address, now this time without going inside the minkube)


(base) user@Dhanupriya-Office ~ % minikube ip

192.168.59.100

(base) user@Dhanupriya-Office ~ % curl 192.168.59.100:31208

Hello from the ${os.hostname()}%    —> Now we can access the deployment from local system using the minikube node IP address and the port number of the service (can also check in web browser)

    Can also check using minikube service command


(base) user@Dhanupriya-Office ~ % minikube service k8s-web-hello-deploy

|-----------|----------------------|-------------|-----------------------------|

| NAMESPACE |         NAME         | TARGET PORT |             URL             |

|-----------|----------------------|-------------|-----------------------------|

| default   | k8s-web-hello-deploy |        3000 | http://192.168.59.100:31208 |

|-----------|----------------------|-------------|-----------------------------|

🎉  Opening service default/k8s-web-hello-deploy in default browser...


# to GET ONLY the URL

(base) user@Dhanupriya-Office ~ % minikube service k8s-web-hello-deploy --url

http://192.168.59.100:31208


## LOAD BALANCER SERVICE - in order to create an external port, we will need to create a LoadBalancer Type service


    First delete our existing service and then create a new one


(base) user@Dhanupriya-Office ~ % k expose deployment k8s-web-hello-deploy --type=LoadBalancer --port=3000

service/k8s-web-hello-deploy exposed

(base) user@Dhanupriya-Office ~ % k get svc

NAME                   TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE

k8s-web-hello-deploy   LoadBalancer   10.99.212.174   <pending>     3000:31930/TCP   3s

kubernetes             ClusterIP      10.96.0.1       <none>        443/TCP          24h


    Here, LoadBalancer Type svc is created. We can see its external port value is <pending>. Since we are in minikube, it will be pending. But when it is deployed to some cloud service provider, its external port will be generated and displayed
    Here, in minikube, this is the same as NodePort type. We can still access using the minikube node Ip address and the service port number as we saw for NodePort type.


(base) user@Dhanupriya-Office ~ % minikube service k8s-web-hello-deploy --url

http://192.168.59.100:31930


## ROLLING UPDATE: ( check in deployment details: we should see Strategy :rolling update)

    Now, if we make some changes in our app, re-build a new image from the updated version and then push it to dockerHub and then re-deploy. K8S will take care of this smooth deployment. 
    K8S will still run the previous pods while it tries to create the new deployment so that the functionality remains intact.
    Lets make changes in our node js app and create new image, push to docker Hub and re-deploy again


    While creating new image, we will need to specify specific tag : (base) user@Dhanupriya-Office k8s-web-hello % docker build . -t budhajit15/k8s-web-hello:2.0.0
    Lets push the updated image : (base) user@Dhanupriya-Office k8s-web-hello % docker push budhajit15/k8s-web-hello:2.0.0
    Now, we can see updated version of the image in the DockerHub


# Set new image - first we will need to set up which image to deploy on which deployment : k set deployment deploy_name container_name=new_image (container_name gives the pods details where we want to deploy)

    After this command, image update will start and rollout updates gets started. We will need to give the following command asap if we want to check the status of the rolling update
    k rollout status deploy k8s-web-hello-deploy


(base) user@Dhanupriya-Office ~ % k set image deployment k8s-web-hello-deploy k8s-web-hello=budhajit15/k8s-web-hello:2.0.0 

deployment.apps/k8s-web-hello-deploy image updated

(base) user@Dhanupriya-Office ~ % k rollout status deploy k8s-web-hello-deploy

Waiting for deployment "k8s-web-hello-deploy" rollout to finish: 2 out of 4 new replicas have been updated...

Waiting for deployment "k8s-web-hello-deploy" rollout to finish: 2 out of 4 new replicas have been updated...

Waiting for deployment "k8s-web-hello-deploy" rollout to finish: 2 out of 4 new replicas have been updated...

Waiting for deployment "k8s-web-hello-deploy" rollout to finish: 2 out of 4 new replicas have been updated...

Waiting for deployment "k8s-web-hello-deploy" rollout to finish: 2 out of 4 new replicas have been updated...

Waiting for deployment "k8s-web-hello-deploy" rollout to finish: 3 out of 4 new replicas have been updated...

Waiting for deployment "k8s-web-hello-deploy" rollout to finish: 3 out of 4 new replicas have been updated...

Waiting for deployment "k8s-web-hello-deploy" rollout to finish: 3 out of 4 new replicas have been updated...

Waiting for deployment "k8s-web-hello-deploy" rollout to finish: 3 out of 4 new replicas have been updated...

Waiting for deployment "k8s-web-hello-deploy" rollout to finish: 1 old replicas are pending termination...

Waiting for deployment "k8s-web-hello-deploy" rollout to finish: 1 old replicas are pending termination...

Waiting for deployment "k8s-web-hello-deploy" rollout to finish: 1 old replicas are pending termination...

Waiting for deployment "k8s-web-hello-deploy" rollout to finish: 3 of 4 updated replicas are available...

deployment "k8s-web-hello-deploy" successfully rolled out


- We can see K8S takes care of rolling out new replicase by updating and then terminating the old replicas keeping the functionality intact.


(base) user@Dhanupriya-Office ~ % k get pods

NAME                                    READY   STATUS    RESTARTS   AGE

k8s-web-hello-deploy-776fc4c894-2hjcc   1/1     Running   0          111s

k8s-web-hello-deploy-776fc4c894-k6mpf   1/1     Running   0          111s

k8s-web-hello-deploy-776fc4c894-khzph   1/1     Running   0          103s

k8s-web-hello-deploy-776fc4c894-wk8ql   1/1     Running   0          100s

(base) user@Dhanupriya-Office ~ % k get svc

NAME                   TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE

k8s-web-hello-deploy   LoadBalancer   10.99.212.174   <pending>     3000:31930/TCP   33m

kubernetes             ClusterIP      10.96.0.1       <none>        443/TCP          24h


    We can now access the pods using node ip and port number: 

(base) user@Dhanupriya-Office ~ % minikube service k8s-web-hello-deploy --url

http://192.168.59.100:31930

(base) user@Dhanupriya-Office ~ % curl 192.168.59.100:31930

VERSION 2 : Hello from the ${os.hostname()}%  


## DELETING a pod

    We can see 4 pods are running, if we try to delete one of the pods. K8S will automatically create a new pod to get the count to 4. 
    This is because we have specified our desired number of replicas to be 4 and K8S will try to keep this intact.


NAME                                    READY   STATUS    RESTARTS   AGE

k8s-web-hello-deploy-776fc4c894-2hjcc   1/1     Running   0          8h

k8s-web-hello-deploy-776fc4c894-k6mpf   1/1     Running   0          8h

k8s-web-hello-deploy-776fc4c894-khzph   1/1     Running   0          8h

k8s-web-hello-deploy-776fc4c894-wk8ql   1/1     Running   0          8h

(base) user@Dhanupriya-Office ~ % k delete pod k8s-web-hello-deploy-776fc4c894-2hjcc

pod "k8s-web-hello-deploy-776fc4c894-2hjcc" deleted

(base) user@Dhanupriya-Office ~ % k get pods

NAME                                    READY   STATUS              RESTARTS   AGE

k8s-web-hello-deploy-776fc4c894-hcfc6   0/1     ContainerCreating   0          4s.  ——> now we can see a new pod is automatically created.

k8s-web-hello-deploy-776fc4c894-k6mpf   1/1     Running             0          8h

k8s-web-hello-deploy-776fc4c894-khzph   1/1     Running             0          8h

k8s-web-hello-deploy-776fc4c894-wk8ql   1/1     Running             0          8h


## DASHBOARD : 

    In minikube, its very simple to launch the dashboard, but when use in Cloud or other full scale cluster, it might not be easy and require multiple setups and configuration
    In minikube, we can launch the dashboard using command minikube dashboard


## DECLARATIVE Approach: till now we have been creating deployments and services using the kubectl commands. This method is called Imperative way, but in real world, they are not created this way.

    In real world, we will write yaml configuration files and then we’ll use kubectl apply commands to create services and deployments. 


Let’s delete our services and deployment that we have created earlier.


## DELETE ALL resources: k delete all —all.   (Note: even after this, the Kubernetes service will be automatically created - the Kubernetes system service)


## PATH to find documentation on how to create different components in yaml file : https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/


## CREATING Deployment.yaml file - in Visual studio, if we have Kubernetes extension installed, then, once we type in the new file ‘deployment’, then kubenetes deployment will automatically pop up, select it and it creates the template

——— Note, this file should be created under the root folder. 

apiVersion: apps/v1

kind: Deployment

metadata:

  name: k8s-web-hellp-deploy

spec:

  selector:

    matchLabels:

      app: k8s-web-hellp-deploy

  template:

    metadata:

      labels:

        app: k8s-web-hellp-deploy

    spec:

      containers:

      - name: k8s-web-hellp-deploy

        image: budhajit15/k8s-web-hell0:2.0.0

        resources:

          limits:

            memory: "128Mi"

            cpu: "500m”.      —> we might need to adjust this if we need to create multiple replicas. (500 means kind of 50%, so if want to create say 4 pods, then we can set it to 250 )

        ports:

        - containerPort: 3000


    Now, after creating this file, we can create deployment using kubectl apply command. 

(base) user@Dhanupriya-Office K8S % k apply -f deployment.yaml           —> -f specifies the filename on which to apply

deployment.apps/k8s-web-hello-deploy created

(base) user@Dhanupriya-Office K8S % k get deployments

NAME                   READY   UP-TO-DATE   AVAILABLE   AGE

k8s-web-hello-deploy   1/1     1            1           5s

(base) user@Dhanupriya-Office K8S % k get pods

NAME                                    READY   STATUS    RESTARTS   AGE

k8s-web-hello-deploy-8459ff95dd-v85zn   1/1     Running   0          7s


    Now we have successfully created the deployment using the yaml file. Here, we  can see there is only one pod. (By default, the number of replicas is 1)
    To scale up the number of replicas, we will need to update our deployment.yaml file to include the number of replicas. (See doc for details, it must be under spec (or Deployment Spec))


spec:

  selector:

    matchLabels:

      app: k8s-web-hello-deploy

  replicas: 4


    Now, after we have included the replicas under the spec, we will write the same apply command to get the changes (NOTE : -f in apply command specifies filename, i.e. which file to deploy)

(base) user@Dhanupriya-Office K8S % k apply -f deployment.yaml

deployment.apps/k8s-web-hello-deploy configured

(base) user@Dhanupriya-Office K8S % k get pods

NAME                                    READY   STATUS    RESTARTS   AGE

k8s-web-hello-deploy-54464bdcd6-g9prk   1/1     Running   0          5s

k8s-web-hello-deploy-54464bdcd6-k4t5s   1/1     Running   0          84s

k8s-web-hello-deploy-54464bdcd6-v765b   1/1     Running   0          5s

k8s-web-hello-deploy-54464bdcd6-z978z   1/1     Running   0          5s


    Now, we can see 4 new pods are created as per what we set up in the yaml file.


## CREATING SERVICES using similar approach:

    First we’ll create a service.yaml file in the same way that we did for deployment and then run the same command using the service.yaml file instead this time


apiVersion: v1

kind: Service

metadata:

  name: k8s-web-hello-svc-deploy     —> should have the same name with the corresponding deployment (this is the label that will bind these deployments and service together)

spec:

  type: LoadBalancer

  selector:

    app: k8s-web-hello-svc-deploy

  ports:

  - port: 3030   —> external port where we want to expose our deployment

    targetPort: 3000   —> internal port which our deployment was accessible


## Now we run the same apply command. Below, we can see our service got created.

(base) user@Dhanupriya-Office K8S % k apply -f service.yaml

service/k8s-web-hello-svc created

(base) user@Dhanupriya-Office K8S % k get svc

NAME                TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE

K8s-web-hello-svc-deploy   LoadBalancer   10.111.156.46   <pending>     3030:31633/TCP   4s

kubernetes          ClusterIP      10.96.0.1       <none>        443/TCP          44h


## DELETING the service and deployment : we can delete both these components at the same time using command: k delete -f deployment.yaml -f service.yaml


(base) user@Dhanupriya-Office K8S % k delete -f deployment.yaml -f service.yaml

deployment.apps "k8s-web-hello-deploy" deleted

service "k8s-web-hello-deploy" deleted

(base) user@Dhanupriya-Office K8S % k get svc

NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE

kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   44h

(base) user@Dhanupriya-Office K8S % k get deployment

No resources found in default namespace.

(base) user@Dhanupriya-Office K8S % 


## MULTIPLE DEPLOYMENTS

    We will try to create multiple deployments, say in one we have a web-deployment with a Load Balancer service exposed to the external world
    And another is a nginx deployment with a ClusterIP service that is exposed only internally in node.
    Our node will have two endpoints / and /nginx, first one to connect to the web-deploy and second to connect to the nginx-deploy
    These deployments can communicate each other to send request and get response from web to nginx deployment (see screenshot for detail architecture setup)


    First lets create another folder similar to k8s-web-hello, this time we name it k8s-web-hello-nginx : this folder will have files and codes related to nginx deployment
    Everything is the same, except few updates on index.mjs file



import express from 'express'

import fetch from 'node-fetch'

import os from 'os'


const app = express()

const port = 3000


app.get('/', (req, res) => {

    const helloMessage = 'Hello from nginx deployment the ${os.hostname()}'

    console.log(helloMessage)

    res.send(helloMessage)

})


—————> this part is added

app.get("/nginx", async (req, res) => {

  const url = 'http://nginx’           —> here this call is using the service name “nginx”. We will create a service name nginx that will connect to the nginx deployment

	  —> can also connect using ClusterIP, but ClusterIP is dynamic, but service name is static, so it is better.

  const response = await fetch(url);

  const body = await response.text();

  res.send(body)

})


app.listen(port, () => {

  console.log(`Web server is listening at port ${port}`)

})



## Now once the updates are done, we will create an image and push it to DockerHub for this nginx deployment


(base) user@Dhanupriya-Office k8s-web-hello-nginx % docker build . -t budhajit15/k8s-web-hello-nginx

[+] Building 26.2s (11/11) FINISHED                                                                            

 => [internal] load build definition from Dockerfile                                                      0.0s

 => => transferring dockerfile: 176B                                                                      0.0s

 => [internal] load .dockerignore                                                                         0.0s

 => => transferring context: 2B                                                                           0.0s

 => [internal] load metadata for docker.io/library/node:alpine                                            5.0s

 => [auth] library/node:pull token for registry-1.docker.io                                               0.0s

 => [internal] load build context                                                                         0.0s

 => => transferring context: 45.73kB                                                                      0.0s

 => [1/5] FROM docker.io/library/node:alpine@sha256:9b435939937b0deef5c1f6fcfd1f265aa7a77574388b671fda3  12.1s

 => => resolve docker.io/library/node:alpine@sha256:9b435939937b0deef5c1f6fcfd1f265aa7a77574388b671fda32  0.0s

 => => sha256:f08168de449131d96a16a9c042f96dc3169678907f120eee8d5ecc10ca75bb48 1.16kB / 1.16kB            0.0s

 => => sha256:5e67b17105720d0c38599a616adcb3f6c66c4bb247a7180032c78e93297e8ea0 6.67kB / 6.67kB            0.0s

 => => sha256:f65aa18165db91da3885baecdb9fd97003870a596214eae012cdad32939d951a 46.26MB / 46.26MB          8.7s

 => => sha256:028cf1f44ab1e1d832e34c329dfcc22800645542ab3bbbad9e7e126b411ce1f9 2.35MB / 2.35MB            2.9s

 => => sha256:fd0328f6bdba7ec736a2c2f798e514297eefffd6653608e0d461799751c59837 449B / 449B                1.3s

 => => sha256:9b435939937b0deef5c1f6fcfd1f265aa7a77574388b671fda322e662744472d 1.43kB / 1.43kB            0.0s

 => => extracting sha256:f65aa18165db91da3885baecdb9fd97003870a596214eae012cdad32939d951a                 3.0s

 => => extracting sha256:028cf1f44ab1e1d832e34c329dfcc22800645542ab3bbbad9e7e126b411ce1f9                 0.2s

 => => extracting sha256:fd0328f6bdba7ec736a2c2f798e514297eefffd6653608e0d461799751c59837                 0.0s

 => [2/5] WORKDIR /app                                                                                    5.2s

 => [3/5] COPY package.json package-lock.json ./                                                          0.1s

 => [4/5] RUN npm install                                                                                 3.3s

 => [5/5] COPY . ./                                                                                       0.1s

 => exporting to image                                                                                    0.3s

 => => exporting layers                                                                                   0.2s

 => => writing image sha256:7eae6d9bb8eeb72cdca1b26a7c3f4f22ace108e01975afcb37ffc41489677275              0.0s 

 => => naming to docker.io/budhajit15/k8s-web-hello-nginx                                                 0.0s


Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them 


## ——> Now we have successfully created image, lets push into Dockehub


(base) user@Dhanupriya-Office k8s-web-hello-nginx % docker push budhajit15/k8s-web-hello-nginx

Using default tag: latest

The push refers to repository [docker.io/budhajit15/k8s-web-hello-nginx]

061f2d2ee0d2: Pushed 

6bde5ca9623c: Pushed 

6baaa272ef16: Pushed 

bbc2b0d7c684: Pushed 

29ddfb506e6b: Mounted from library/node 

1dd574bd2c87: Mounted from library/node 

d101fffc6eaf: Mounted from library/node 

994393dc58e7: Mounted from budhajit15/k8s-web-hello 

latest: digest: sha256:43d434f0b2d34d6fa4d7ac61ce621c773f952ffd6961ee9b4b1302b3f16b9f8a size: 1992


    Now, I can see the image in the docker hub now.


## Now lets try to put the deployment and service yaml files in just one file (I’ll name the file k8s-web-to-nginx)

    For this, I create the above file and copy contents and then rename the app name or labels
    Similarly, create another file for nginx deployment, an nginx yaml file. Note in this, we have to specify the service name “nginx” as we are using this name to call this service
    Now after we have created two yaml files for these two deployments, lets use apply command to create the deployments.


    First lets check if there aren’t any deployments and pods and then create the deployments and services using these files


(base) user@Dhanupriya-Office K8S % k apply -f k8s-web-to-nginx.yaml -f nginx.yaml

service/k8s-web-nginx created

deployment.apps/k8s-web-nginx created

service/nginx created

deployment.apps/nginx created

(base) user@Dhanupriya-Office K8S % k get deployments

NAME            READY   UP-TO-DATE   AVAILABLE   AGE

k8s-web-nginx   0/3     3            0           7s

nginx           0/4     4            0           7s

(base) user@Dhanupriya-Office K8S % k get svc

NAME            TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE

k8s-web-nginx   LoadBalancer   10.101.59.179   <pending>     3333:31758/TCP   18s

kubernetes      ClusterIP      10.96.0.1       <none>        443/TCP          2d9h

nginx           ClusterIP      10.109.123.5    <none>        80/TCP           18s

(base) user@Dhanupriya-Office K8S % k get pods

NAME                             READY   STATUS              RESTARTS   AGE

k8s-web-nginx-649ff6bccc-b4swl   0/1     ContainerCreating   0          25s

k8s-web-nginx-649ff6bccc-jcjjv   0/1     ContainerCreating   0          25s

k8s-web-nginx-649ff6bccc-jjr4d   0/1     ContainerCreating   0          25s

nginx-6ddcfb665f-2n9wn           0/1     ContainerCreating   0          25s

nginx-6ddcfb665f-2rnvf           1/1     Running             0          25s

nginx-6ddcfb665f-9gtbx           0/1     ContainerCreating   0          25s

nginx-6ddcfb665f-nnhgv           0/1     Pending             0          25s


## Access the services and deployments

    Now that we have created, let’s first try to access the web deploy service and then from there, we will try to connect to nginx svc using it’s name

(base) user@Dhanupriya-Office K8S % minikube service k8s-web-nginx

|-----------|---------------|-------------|-----------------------------|

| NAMESPACE |     NAME      | TARGET PORT |             URL             |

|-----------|---------------|-------------|-----------------------------|

| default   | k8s-web-nginx |        3333 | http://192.168.59.100:31758 |

|-----------|---------------|-------------|-----------------------------|

🎉  Opening service default/k8s-web-nginx in default browser...


— now, I’m able to successfully access the web deploy. Now, lets add the route /nginx to the URL and then try to access the nginx service

http://192.168.59.100:31758/nginx is able to successfully access the nginx svc.


## TAKE :

    So basically we are able to connect from one deployment (web-deploy) to another deployment (nginx) in our case using the service name
    Such resolution of the service name to IP address is performed by the Internal service of the Kubernetes called DNS.
    We can also check this by going into one of the pods and do look dns


(base) user@Dhanupriya-Office K8S % k exec k8s-web-nginx-649ff6bccc-b4swl -- nslookup nginx

Server:         10.96.0.10

Address:        10.96.0.10:53


Name:   nginx.default.svc.cluster.local

Address: 10.109.123.5


    Now, if we look at the services again

(base) user@Dhanupriya-Office K8S % k get svc

NAME            TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE

k8s-web-nginx   LoadBalancer   10.101.59.179   <pending>     3333:31758/TCP   16m

kubernetes      ClusterIP      10.96.0.1       <none>        443/TCP          2d9h

nginx           ClusterIP      10.109.123.5    <none>        80/TCP           16m


    We can see, the IP address of nginx is the same as the one in the look up, meaning this is the IP address that K8S gets resolved for this deployment.
    We can also access nginx from one of the pods this way also:


(base) user@Dhanupriya-Office ~ % k exec k8s-web-nginx-649ff6bccc-b4swl -- wget -qO- http://nginx

<!DOCTYPE html>

<html>

<head>

<title>Welcome to nginx!</title>

<style>

html { color-scheme: light dark; }

body { width: 35em; margin: 0 auto;

font-family: Tahoma, Verdana, Arial, sans-serif; }

</style>

</head>

<body>

<h1>Welcome to nginx!</h1>

<p>If you see this page, the nginx web server is successfully installed and

working. Further configuration is required.</p>


<p>For online documentation and support please refer to

<a href="http://nginx.org/">nginx.org</a>.<br/>

Commercial support is available at

<a href="http://nginx.com/">nginx.com</a>.</p>


<p><em>Thank you for using nginx.</em></p>

</body>

</html>


    This connects to the nginx server and retrieve the root page contents


## now lets delete these services and deployments


(base) user@Dhanupriya-Office K8S % k delete -f nginx.yaml -f k8s-web-to-nginx.yaml 

service "nginx" deleted

deployment.apps "nginx" deleted

service "k8s-web-nginx" deleted

deployment.apps "k8s-web-nginx" deleted

(base) user@Dhanupriya-Office K8S % k get svc

NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE

kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   2d9h

(base) user@Dhanupriya-Office K8S % k get pods

No resources found in default namespace.


## DELETING minikube node

# check status


(base) user@Dhanupriya-Office ~ % minikube status           

minikube

type: Control Plane

host: Running

kubelet: Running

apiserver: Running

kubeconfig: Configured


# stop minikube server

(base) user@Dhanupriya-Office ~ % minikube stop

✋  Stopping node "minikube"  ...

🛑  1 node stopped.


# finally deleting minikube

(base) user@Dhanupriya-Office ~ % minikube delete

🔥  Deleting "minikube" in virtualbox ...

💀  Removed all traces of the "minikube" cluster.


## we can restart again using minikube start command: minikube start —driver=virtualbox